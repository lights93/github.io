---
layout: post
title: "컴퓨터 비전을 위한 딥러닝"
date: 2018-11-14
excerpt: "컴퓨터 비전을 위한 딥러닝"
tags: [Keras, deepLearning]
comments: true
---

# 5. 컴퓨터 비전을 위한 딥러닝

## 5.1 합성곱 신경망 소개

* 5.1.1 합성곱 연산
	* Dense 층은 입력 특성 공간에 있는 전역 패턴을 학습하지만 합성곱 층은 지역 패턴을 학습합니다.
	* 컨브넷의 두가지 흥미로운 성질
		1. 학습된 패턴은 평행 이동 불변성을 가진다.
			* 완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 한다.
			* 적은 수의 훈련 샘플을 사용해서 일반화 능력을 가진 표현을 학습할 수 있다.
		2. 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있다.
			* 첫 번째 합성곱 층이 에지 같은 작은 지역 패턴을 학습
			* 두 번째 합성곱 층은 첫 번째 층의 특성으로 구성된 더 큰 패턴을 학습하는 방식
	* 합성곱 연산은 특성 맵(feature map)이라고 부르는 3D 텐서에 적용됨
	* 이 텐서는 2개의 공간 축(높이와 넓이)과 깊이 축(채널 축)으로 구성됨
	* 합성곱 연산은 입력 특성 맵에서 작은 패치들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 출력 특성 맵(output feature map)을 만든다.
	* 필터: 깊이 축의 채널, 합성곱 층에서 사용하는 모델 파라미터
	* 합성곱의 핵심적인 2개의 파라미터
		* 입력으로부터 뽑아낼 패치의 크기
		* 특성 맵의 출력 깊이
	* Conv2D(output_depth, (window_height, window_width))
	* 출력 높이와 넓이는 입력의 높이, 넓이와 다를 수 있습니다.
		* 경계 문제. 입력 특성 맵에 패딩을 추가하여 대응 가능
		* 스트라이드의 사용 여부에 따라 다름
	* 경계 문제와 패딩 이해하기
		* 입력과 동일한 높이와 넓이를 가진 출력 특성 맵을 얻고 싶다면 패딩을 사용할 수 있다.
	* 합성곱 스트라이드 이해하기
		* 두 번의 연속적인 윈도우 사이의 거리
		* 스트라이드 2를 사용했다는 것은 특성 맵의 넓이와 높이가 2의 배수로 다운샘플링되었다는 뜻
* 5.1.2 최대 풀링 연산
	* 강제적으로 특성 맵을 다운샘플링하는 것이 최대 풀링의 역할
	* 최대 풀링은 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채녈벌로 최댓값을 출력
	* 합성곱과 가장 큰 차이점은 최대 풀링은 보통 2X2 윈도우와 스트라이드 2를 사용하여 특성 맵을 절반 크기로 다운샘플링한다는 것
	* 왜 최대 풀링 층을 빼고 큰 특성 맵을 계속 유지하지 않을까요??
		1. 특성의 공간적 계층 구조를 학습하는 데 도움이 되지 않습니다.
		2. 최종 특성 맵은 22 X 22 X 64 = 30976개의 가중치를 가진다. -> 너무 많음!!
		* 그래서 사용하는 이유는 처리할 특성 맵의 가중치 개수를 줄이기 위해서
		* 그리고 연속적인 합성곱 층이 점점 커진 윈도우를 통해 바라보도록 만들어 필터의 공간적인 계층 구조를 구성
	* 최대 풀링이 다른 방법들보다 더 잘 작동하는 이유는 특성이 특성 맵의 각 타일에서 어떤 패턴이나 개념의 존재 여부를 인코딩하는 경향이 있기 때문에
	* 가장 납득할 만한 서브샘플링 전략은 먼저 조밀한 특성 맵을 만들고 그다음 작은 패치에 대해서 최대로 활성화된 특성을 고르는 것
* 5.2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기
	* 5.2.1 작은 데이터셋 문제에서 딥러닝의 타당성
		* 많은 샘플이 의미하는 것은 상대적임
		* 딥러닝 모델은 태생적으로 매우 다목적(대규모 데이터셋에서 훈련시킨 이미지 분류 모델이나 스피치-투-텍스트 모델을 조금만 변경해서 완전히 다른 문제에 재사용 가능)
	* 5.2.2 데이터 내려받기
	* 5.2.3 네트워크 구성하기
	* 5.2.4 데이터 전처리
		1. 사진 파일 읽기
		2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩
		3. 부동 소수 타입의 텐서로 변환
		4. 픽셀 값의 스케일을 [0, 1] 사이로 조정
		* ImageDataGenerator 클래스는 디스크에 있는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꾸어주는 파이썬 제너레이터를 만들어 줌
		* fit_generator 메서도는 fit메소드와 동일하되 데이터 제너레이터를 사용할 수 있다.
		* steps_per_epoch 매개변수로 제너레이터로부터 얼마나 많은 샘플을 뽑을 것인지 알려줌
		* validation_steps로 얼마나 많은 배치를 추출하여 평가할지 지정
		* 훈련 샘플의 수가 적기 떄문에 과대적합 발생
		* 데이터 증식으로 과대적합 해결
	* 5.2.5 데이터 증식 사용하기
		* 데이터 증식은 기존 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법
		* 훈련할 때 모델이 정확히 같은 데이터를 두 번 만나지 않도록 하는 것이 목표
		```
		datagen = ImageDataGenerator(
			rotation_range=20, # 랜덤하게 사진을 회전시킬 각도 범위(0~180)
			width_shift_range=0.1, # 수평으로 랜덤하게 평행 이동시킬 범위
			height_shift_range=0.1, # 수직으로 랜덤하게 평행 이동시킬 범위
			shear_range=0.1, # 랜덤하게 전단 변환을 적용할 각도 범위
			zoom_range=0.1, # 랜덤하게 사진을 확대할 범위
			horizontal_flip=True, # 랜덤하게 이미지를 수평으로 뒤집음
			fill_mode='nearest') # 회전이나 가로/세로 이동으로 인해 새롭게 생성해야 할 픽셀을 채울 전략
		```
		* 적은 수의 언본 이미지에서 만들어졌기 때문에 데이터 증식을 사용해도 상호 연관성이 크다.
		* 그래서 Dropout 추가
* 5.3 사전 훈련된 컨브넷 사용하기
	* 사전 훈련된 네트워크는 일반적으로 대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크
	* 학습된 특성을 다른 문제에 적용할 수 있는 이런 유연성은 이전의 많은 얕은 학습 방법과 비교했을 때 딥러닝의 핵심 장점
	* VGG16 구조 사용
	* VGG16은 조금 오래되었고 최고 수준의 성능에는 못 미치며 최근의 다른 모델보다는 조금 무겁지만 새로운 개념을 도입하지 않고 이해하기 쉽기 때문에 선택
	* 5.3.1 특성 추출
		* 특성 추출은 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아내는 것
		* 컨브넷은 이미지 분류를 위해 두 부분으로 구성됨
		* 컨브넷의 경우 특성 추출은 사전헤 훈련된 네트워크의 합성곱 기반 층을 선택하여 새로운 데이터를 통과시키고, 그 출력으로 새로운 분류기를 훈련
		* 왜 합성곱 층만 재사용?? -> 합성곱 층에 의해 학습된 표현이 더 일반적이어서 재사용 가능
		* 컨브넷의 특성 맵은 사진에 대한 일반적인 콘셉트의 존재 여부를 기록한 맵
		* 분류기에서 학습한 표현은 모델이 훈련된 클래스 집합에 특화
		* 특정 합성곱 층에서 추출한 표현의 일반성 수준은 모델에 있는 층의 깊이에 달려 있다.
		* VGG16 네트워크의 합성곱 기반 층을 사용하여 강아지와 고양이 이미지에서 유용한 특성 분류
			* 데이터 증식을 사용하지 않는 빠른 특성 추출
				* 새로운 데이터셋에서 합성곱 기반 층을 실행하고 출력을 넘파이 배열로 디스크에 저장 후, 독립된 완전 연결 분류기에 입력으로 사용
				* 많은 비율로 드롭아웃을 사용했음에도 훈련을 시작하면서 거의 바로 과대적합
			* 데이터 증식을 사용한 특성 추출
				* 준비한 모델 위에 Dense 층을 쌓아 확장
				* 동결: 훈련하는 동안 가중치가 업데이트되지 않도록 막는다
				* 검증 정확도는 이전과 비슷하지만 처음부터 훈련시킨 소규모 컨브넷보다 과대적합이 줄어듬
	* 5.3.2 미세 조정
		* 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해제하고 모델에 새로 추가한 층과 함께 훈련하는 것
		* 미세조정 단계
			1. 사전에 훈련된 기반 네트워크 위에 새로운 네티워크 추가
			2. 기반 네트워크를 동결
			3. 새로 추가한 네트워크 훈련
			4. 기반 네트워크에서 일부 층의 동결 해제
			5. 동결을 해제한 층과 새로 추가한 층을 함께 훈련
		* 미세 조정할 합성곱 층을 정할 때 고려해야 할 사항
			1. 합성곱 기반 층에 있는 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 인코딩하고, 상위 층은 좀 더 특화된 특성을 인코딩 -> 그래서 상위 층이 더 효과적
			2. 훈련해야 할 파라미터가 많을수록 과대적합의 위험이 커짐
		* 정확도에 영향을 미치는 것은 손실 값의 분포이지 평균이 아님 -> 정확도는 모델이 예측한 클래스 확률이 어떤 임계 값을 넘었는지에 대한 결과
	* 5.3.3 정리
		* 컨브넷은 컴퓨터 비전 작업에 가장 뛰어난 머신 러닝 모델
		* 작은 데이터셋에서는 과대적합이 큰 문제(데이터 증식은 이미지 데이터를 다룰 때 과대적합을 막을 수 있는 강력한 방법)
		* 특성 추출 방식으로 새로운 데이터셋에 기존 컨브넷을 쉽게 재사용 가능
		* 미세 조정은 기존 모델에서 사전에 학습한 표현의 일부를 새로운 문제에 적응시킴
* 5.4 컨브넷 학습 시각화
	* 5.4.1 중간층의 활성화 시각화하기
		* 어떤 입력이 주어졌을 때 네트워크에 있는 여려 합성곱과 풀링 층이 출력하는 특성 맵을 그리는 것
		* 층에서 추출한 특성은 층의 깊이를 따라 점점 더 추상적으로 변함
		* 높은 층의 활성화는 특정 입력에 관한 시각적 정보가 점점 줄어들고 타깃에 관한 정보가 점점 더 증가
	* 5.4.2 컨브넷 필터 시각화하기
		* 각 필터가 반응하는 시각적 패턴을 그려보는 것
		* 특성 합성곱 층의 한 필터 값을 최대화하는 손실 함수를 정의
		* 컨브넷의 각 층은 필터의 조합으로 입력을 표현할 수 있는 일련의 필터를 학습
	* 5.4.3 클래스 활성화의 히트맵 시각화하기
		* 특정 출력 클래스에 대해 입력 이미지의 모든 위치를 계산한 2D 점수 그리드
		* 입력 이미지가 각 채널을 활성화하는 정도에 대항 공간적인 맵을 클래스에 대한 각 채널의 중요도로 가중치를 부여하여 입력 이미지가 클래스를 활성화나는 정도에 대한 공간적인 맵을 만드는 것
* 5.5 요약
	* 컨브넷은 시각적인 분류 문제를 다루는 데 최상의 도구
	* 컨브넷은 우리가 보는 세상을 표현하기 위한 패턴의 계층 구조와 개념을 학습
	* 학습된 표현은 쉽게 분석 가능
	* 이미지 분류 문제를 풀기 위해 자신만의 컨브넷을 처음부터 훈련시킬 수 있음
	* 과대적합을 줄이기 위해 데이터 증식 사용
	* 사전 훈련된 컨브넷을 사용하여 특성 추출과 미세 조정
	* 컨브넷이 학습한 필터를 시각화 가능
		