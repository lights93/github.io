---
layout: post
title: "머신 러닝의 기본 요소"
date: 2018-11-11
excerpt: "머신 러닝의 기본 요소"
tags: [Keras, deepLearning]
comments: true
---

# 4. 머신 러닝의 기본 요소

## 4.1 머신러닝의 네 가지 분류

* 4.1.1 지도 학습
	* 샘플 데이터가 주어지면 알고 있는 타깃에 입력 데이터를 매핑하는 방법을 학습
	* 이미진 분류, 문자 판독, 음성 인식, 언어 번역 등
* 4.1.2 비지도 학습
	* 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾음
	* 차원 축소, 군집
* 4.1.3 자기 지도 학습
	* 학습 과정에 사람이 개입하지 않는 지도 학습
	* 경험적인 알고리즘을 사용해서 입력 데이터로부터 생성
	* 오토인코더
* 4.1.4 강화 학습
	* 에이전트는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습
	* 알파고 등

## 4.2 머신 러닝 모델 평가

* 4.2.1 훈련, 검증, 테스트 세트
	* 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 평가, 모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한 번 모델 테스트
	* 3개의 세트를 사용하는 이유
		* 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문에
			* 하이퍼파라미터(층의 수나 층의 유닛 수)
			* 검증 세트에서 모델의 성능을 평가하여 튜닝을 수행
			* 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트 모델을 직접 훈련하지 않더라도 빠르게 검증 세트에 과대적합될 수 있다.
			* 정보 누설: 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 대한 정보가 모델로 새는 것
			* 그래서 완전히 새로운 데이터인 테스트 세트가 필요
	* 단순 홀드아웃 검증
		* 데이터의 일정량을 테스트 세트로 떼어 놓는다.
		* 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있다.
	* k-겹 교차 검증
		* 데이터를 동일한 크기를 가진 K개 분할로 나눈다.
		* 각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가
		* 최종 점수는 K개의 점수를 평균
		* 모델의 성능이 데이터 분할에 따라 편차가 클 때 좋음
	* 셔플링을 사용한 k-겹 교차 검증
		* 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용
		* k-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞음
		* 최종 점수는 모든 k-겹 교차 검증을 실행해서 얻은 점수의 평균
* 4.2.2 기억해야 할 것
	* 대표성 있는 데이터
		* 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 한다.
	* 시간의 방향
		* 과거로 부터 미래를 예측하려고 한다면 데이터를 섞지 말고, 미래를 테스트 셋으로 해야 한다.
	* 데이터 중복
		* 훈련 세트와 검증 세트에 데이터 포인트가 중복되면 안 됨

## 4.3 데이터 전처리, 특성 공학, 특성 학습

* 4.3.1 신경망을 위한 데이터 전처리
	* 벡터화
		* 데이터 벡터화: 모든 입력과 타깃을 텐서로 변환하는 것
	* 값 정규화
		* 일반적으로 비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하는 것은 위험
		* 네트워크를 쉽게 학습시키기 위한 특징
			1. 작은 값(대부분의 값이 0~1 사이)
			2. 균일해야 함(모든 특성이 대체로 비슷한 범위)
	* 누락된 값 다루기
		* 일반적으로 0이 사전에 정의된 의미 있는 값이 아니라면 누락된 값을 0으로 입력해도 괜찮음
* 4.3.2 특성 공학
	* 데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계
	* 좋은 특성은 적은 자원을 사용하여 문제를 더 멋지게 풀어낼 수 있음
	* 좋은 특성은 더 적은 데이터로 문제를 풀 수 있음

## 4.4 과대적합과 과소적합

* 머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기
* 최적화는 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정
* 일반화는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미
* 규제: 과대적합을 피하는 처리 과정
* 4.4.1 네트워크 크기 축소
	* 과대적합을 막는 가장 단순한 방법은 모델의 크기, 즉 모델에 있는 학습 파라미터의 수를 줄이는 것
	* 딥러닝에서 모델에 있는 학습 파라미터의 수를 종종 모델의 용량이라고 말함
	* 기억 용랑이 많아 일대일 매핑으로 완벽하게 학습한다면 일반화 능력이 없음
	* 기억 용량이 부족하다면 과소적합 발생
	* 너무 않은 용량과 충분하지 않은 용랑 사이의 절충점을 찾아야 함
	* 용량이 많은 네트워크일수록 더 빠르게 훈련 데이터를 모델링할 수 있지만 과대적합에 민감해진다.
* 4.4.2 가중치 규제 추가
	* 간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높음
	* 간단한 모델이란 파라미터 값 분포의 엔트로피가 작은 모델(또는 적은 수의 파라미터를 가진 모델)
	* 가중치 규제: 네트워크의 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것
	* 네트워크의 손실 함수에 큰 가중치에 연관된 비용을 추가
	* 두가지 형태의 비용
		* L1 규제: 가중치의 절댓값에 비레하는 비용이 추가
		* L2 규제(가중치 감쇠): 가중치의 제곱에 비례하는 비용이 추가
* 4.4.3 드롭아웃 추가
	* 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킨다.(0으로 만든다)
	* ex. [0.2, 0.5. 1.3, 0.8, 1.1] -> [0, 0.5. 1.3, 0, 1.1]
	* 드롭아웃 비율은 0이 될 특성의 비율, 보통 0.2에서 0.5 사이
	* 테스트 단계에서는 어떤 유닛도 드롭아웃되지 않고, 층의 출력을 드롭아웃 비율에 비례하여 줄여줌
	* 각 샘플에 대해 뉴런의 일부를 무작위하게 제거하면 뉴런의 부정한 협업을 방지하고 결국 과대적합을 감소시킨다.
	* 층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패텅을 깨뜨리는 것

## 4.5 보편적인 머신 러닝 작업 흐름

* 4.5.1 문제 정의와 데이터셋 수집
	* 문제 정의
		* 입력 데이터는 무엇?
		* 어떠한 것을 예측?
		* 가용 데이터의 유무
		* 문제의 종류??(이진 분류, 다중 분류, 스칼라 회귀 ... )
	* 가설 세우기
		* 주어진 입려그로 출력을 예측할 수 있다고 가설을 세움
		* 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세움
	* 머신 러닝은 훈련 데이터에 있는 패턴을 기억하기 위해서만 사용함
* 4.5.2 성공 지표 선택
	* 정확도? 재현율? 정밀도? -> 지표 선택!
* 4.5.3 평가 방법 선택
	* 홀드아웃 검증 세트 분리/K-겹 교차 검증/반복 K-겹 교차 검증 중 하나 선택
* 4.5.4 데이터 준비
	* 텐서로 구성
	* 작은 값으로 스케일 조정
	* 정규화
	* 특성 공학
* 4.5.5 기본보다 나은 모델 훈련하기
	* 일이 잘 진행된다고 가정하면 첫 번째 모델을 만들기 위해 세 가지 중요한 선택
		1. 마지막 층의 활성화 함수
		2. 손실 함수
		3. 최적화 설정
	* 모델에 맞는 마지막 층의 활성화 함수와 손실 함수 선택
		* 이진 분류/시그모이드/binary_crossentropy
		* 단일 레이블 다중 분류/소프트맥스/categorical_crossentropy
		* 다중 레이블 다중 분류/시그모이드/binary_crossentropy
		* 임의 값에 대한 회귀/없음/mse
		* 0과 1 사이 값에 대한 회귀/시그모이드/mse 또는 binary_crossentropy
* 4.5.6 몸집 키우기: 과대적합 모델 구축
	* 과소 적합과 과대적합 사이, 즉 과소용랑과 과대용랑의 경계에 적절히 위치한 모델을 찾기 위해 직접 확인
	* 먼저 과대적합 찾기
		1. 층을 추가
		2. 층의 크기를 키움
		3. 더 많은 에포크 동안 훈련
	* 다음으로 과소적합도 아니고 과대적합도 아닌 이상적인 모델에 가능한 가깝도록 만든다.
* 4.5.7 모델 규제와 하이퍼파라미터 튜닝
	* 드롭아웃 추가
	* 층을 추가하거나 제거해서 다른 구조를 시도
	* L1이나 L2 또는 두 가지 모두 추가
	* 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도(층의 유닉 수나 옵티마이저의 학습률 등)
	* 선택적으로 특성 공학 시도(새로운 특성 추가 또는 유용하지 않을 것 같은 특성 제거)
* 4.6 요약
	* 주어진 문제와 훈련할 데이터를 정의. 데이터를 수집하고 필요하면 레이블을 태깅
	* 성공을 어떻게 측정할지 선택
	* 평가 방법 결정
	* 단순한 랜덤 선택 모델보다 나은 통계적 검정력 있는 첫 번째 모델을 만든다
	* 과대적합된 모델을 만든다.
	* 검증 데이터의 성능에 기초하여 모델에 규제를 적용하고 하이퍼파리미터를 튜닝