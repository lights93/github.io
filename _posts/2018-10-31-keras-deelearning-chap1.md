
---
layout: post
title: "케라스 창시자에게 배우는 딥러닝"
date: 2018-10-31
excerpt: "딥러닝이란?"
tags: [Keras, deepLearning]
comments: true
---

# 1. 딥러닝이란 무엇인가?

## 1.1 인공 지능과 머신 러닝, 딥러닝

* 1.1.1 인공 지능
	* 인공지능 : **보통의 사람이 수행하는지능적인 작업을 자동화하기 위한 연구 활동**
	* **심볼릭 AI** : 명시적인 규칙을 충분하게 많이 만들어 지식을 다루면 인간 수준의 인공 지능을 만들 수 있음
* 1.1.2 머신 러닝
	* 우리가 어떤 것을 작동시키기 위해 어떻게 명령할 지 알고 있는 것 이상을 컴퓨터가 처리하는 것이 가능한가?
	* 특정 작업을 수행하는 법을 스스로 학습할 수 있는가?
	* 머신 러닝에서는 데이터와 이 데이터로부터 기대되는 해답을 입력하면 규칙이 출력
* 1.1.3 데이터에서 표현을 학습하기
	* **입력 데이터 포인트** : 문제가 음성 인식이라면 데이터 포인트는 사람의 대화가 녹음된 사운드 파일
	* **기대 출력**: 음성 인식 작업에서 사람이 사운드 파일을 듣고 옮긴 글
	* **알고리즘의 성능을 측정하는 방법**: 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정하기 위해 필요함 => 학습
	* 입력 데이터를 기반으로 기대 출력에 가깝게 만드는 유용한 표현을 학습하는 것
	* **표현(representaion)**: 데이터를 인코딩하거나 묘사하기 위해 데이터를 바라보는 다른 방법
	* **학습(learning)**: 더 나은 표현을 찾는 자동화된 과정
* 1.1.4 딥러닝에서 '딥'이란 무엇일까?
	* **딥러닝(층 기반 표현 학습, 계층적 표현 학습)**: 머신 러닝의 특정한 한 분야로서 연속된 층에서 점진적으로 의미 있는 표현을 배우는 데 강점이 있으며, 데이터로부터 표현을 학습하는 새로운 방식
	* 딥은 연속된 층으로 표현을 학습한다는 개념
	* 모델의 깊이: 데이터로부터 모델을 만드는 데 얼마나 많은 층을 사용했는가
	* 얕은 학습(shallow learning): 1~2개의 데이터 표현 층을 학습
	* 기본 층을 겹겹이 쌓아 욜러 구성한 신경망(neural network)이라는 모델을 사용하여 표현 층을 학습
	* 심층 신경망을 정보가 연속된 필터(층)을 통과하면서 순도 높게(유용하게) 정제되는 다단계 정보 추출 작업
* 1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기
	* 층에서 입력 데이터가 처리되는 상세 내용은 일련의 숫자로 이루어진 층의 **가중치**에 저장
	* 어떤 층에서 일어나는 변환은 그 층의 가중치를 파라미터로 가지는 함수로 표현됨
	* 학습은 주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미
	* **손실 함수(목적 함수, 비용 함수)**: 신명강미 한 샘플에 대해 얼마나 잘 예측했는지 측정하기 위해 손실 함수가 신경망의 예측과 진짜 타깃의 차이를 계산하는 함수
	* **역전파(Backpropagation)**: 손실 점수를 피드백 신호로 사용하여 현재 샘플의 손실 점수가 감소되는 방향으로 가중치 값을 조금씩 수정하는 것
	* **옵티마이저(optimizer)**: 역전파 알고리즘을 구현한 것
	* **훈련 반복(training loop)**: 네트워크가 모든 샘플을 처리하면서 가중치가 조금씩 올바른 방향으로 조정되고 손실 점수가 감소하는 것
* 1.1.6 지금까지 딥러닝의 성과
	* 지각과 자연어 인식, 형식 추론 등 ...
* 1.1.7 단기간의 과대 선전을 믿지 말자
	* 1960년대 심볼릭 AI -> 첫 번째 AI 겨울
	* 1980년대 전문가 시스템 -> 두 번째 AI 겨울
	* 이번에도..?
* 1.1.8 AI에 대한 전망
	* 단기간의 과대 선전을 믿지 말고 장기 비전을 믿어라!

## 1.2 딥러닝 이전: 머신 러닝의 간략한 역사

* 1.2.1 확률적 모델링(probabilistic modeling)
	* 나이브 베이즈 알고리즘(Naive Bayes): 입력 데이터의 특성이 모두 독립적이라고 가정하고 베이즈 정리를 적용하는 머신 러닝 분류 알고리즘
	* 로지스틱 회귀(logistic regression): 회귀가 아닌 분류 알고리즘
	* 회귀(regression)는 연속적인 숫자를 예측하는 것, 분류는 여러 클래스 중 하나를 예측하는 것
* 1.2.2 초창기 신경망
	* LeNet: 초창기 합성곱 신경망(convolution neural network)과 역전파를 연결
* 1.2.3 커널 방법
	* 커널 방법(Kernel Method): 분류 알고리즘의 한 종류, 서포트 벡터 머신이 가장 유명함
	* **서포트 벡터 머신(Supprort Vector Machine, SVM)** : 분류 문제를 해결하기 위해 2개의 다른 범주에 속한 데이터 포인트 그룹 사이에 결정 경계(decision boundary)를 찾는다.
	* SVM이 결정 경계를 찾는 과정
		1. 결정 경계가 하나의 초평면으로 표현될 수 있는 새로운 고차원 표현으로 데이터를 매핑
		2. 초평면과 각 클래스의 가장 가까운 데이터 포인트 사이의 거리가 최대가 되는 최선의 결정 경계를 찾음(**마진 최대화(maximizing the margin)**)
	* 데이터를 고차원 표현으로 매핑하는 기법이 이론상으로는 좋아 보이지만 실제로는 구현하기 어려운 경우가 많기 때문에 커널 기법 등장
	* 새롭게 표현된 공간에서 좋은 결정 초평면을 찾기 위해 새로운 공간에 대응하는 데이터 포인트의 좌표를 실제로 구하지 않고 거리만 계산(**커널 함수**)
	* 커널 함수는 직접 만들어야 한다.
	* SVM은 간단한 분류 문제에 대해 최고 수준의 성능을 달성했고 이론을 이해하고 설명하기 쉬워 인기를 끌었었다.
	* 하지만 SVM은 대용량의 데이터셋에 확장되기 어렵고, 자각에 관련된 문제에서 좋은 성능 X
* 1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신
	* **결정 트리(decision tree)**: 입력 데이터 포인트를 분류하거나 주어진 입력에 대해 출력 값을 예측
	* **랜덤 포레스트(random forest)**: 서로 다른 결정 트리를 많이 만들고 그 출력을 앙상블하는 방법 사용
	* **그래디언트 부스팅 머신(gradient boosting machine)**: 결정트리 앙상블 + 그래디언트 부스팅(이전 모델에서 놓친 데이터 포인트를 보완하는 새로운 모델을 반복적으로 훈련)
* 1.2.5 다시 신경망으로
	* 심층 합성곱 신경망(deep convolutional neural network): 모든 문제에 적용 가능
* 1.2.6 딥러닝의 특징
	* **특성 공학(feature engineering)**: 유용한 표현을 수동을 만드는 것
	* 딥러닝은 머신 러닝에서 가장 중요한 단계인 특성 공학을 완전히 자동화
	* 고도의 다단계 작업 과정을 하나의 간단한 엔드-투-엔드 딥러닝 모델로 대체 가능
	* **얕은 학습 방법은 연속돈 표현 층을 독립적으로 학습하기 때문에 전체 층의 개수와 상관없이 항상 동일하게 첫 번째 층이 동일한 양의 정보를 학습하므로 이후에 연속되는 층은 전체 모델에 기여하는 바가 점차 줄어든다.(이전 층에 의존)**
	* **딥러닝은 모든 표현 층을 순차적이 아니라 동시에 공동으로 학습하기 때문에 모델이 내부 특성 하나에 맞추어질 때마다 이에 의존하는 다른 모든 특성이 사람이 개입하지 않아도 자동으로 변화에 적응(이전 층에 의존 X)**
	* 딥러닝이 데이터로부터 학습하는 방법의 두 가지 중요한 특징
		1. **층을 거치면서 점진적으로 더 복잡한 표현이 만들어진다.**
		2. **이런 점진적인 중간 표현이 공동으로 학습된다.**
* 1.2.7 머신 러닝의 최근 동향
	* 케라스, XGBoost

## 1.3 왜 딥러닝일까? 왜 지금일까?

* 1.3.1 하드웨어
	* GPU의 등장
* 1.3.2 데이터
	* 인터넷(유튜브, 위키피디아) 등으로 데이터가 많아짐 ( 무어의 법칙 )
* 1.3.3 알고리즘
	* 신경망의 층에 더 잘 맞는 **활성화 함수(activation function)**
	* 층별 사전 훈련을 불필요하게 만든 **가중치 초기화(weight initilization)** 방법
	* RMSProp과 Adam 같은 더 좋은 **최적화** 방법
* 1.3.4 새로운 투자의 바람
	* 금전적 투자, 트렌드
* 1.3.5 딥러닝의 대중화
	* 도구들의 대중화: 씨아노(Theano), 텐서플로(Tensorflow), 케라스
* 1.3.6 지속될까?
	* 딥러닝의 특징
		1. **단순함**: 특성 공학 필요 X, 엔드-투-엔드
		2. **확장성**: 쉽게 병렬화, 작은 배치 데이터
		3. **다용도와 재사용성**: 추가되는 데이터로도 훈련 가능
	* 앞으로 몇 년은 더 갈 듯
